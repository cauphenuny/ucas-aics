# -*- coding: utf-8 -*-
from __future__ import print_function
import argparse
import codecs
import os
import random
import time
import numpy as np

import torch
from hyperparams import Hyperparams as hp
from data_load import TestDataSet, load_de_vocab, load_en_vocab
from nltk.translate.bleu_score import corpus_bleu
from AttModel import AttModel
from torch.autograd import Variable

try:
    import cnmix
except ImportError:
    print("train without cnmix")


def eval(args):
    # Load data
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

    #TODO：调用函数加载德语词表
    de2idx, idx2de = ____________________________
    #TODO：调用函数加载英语词表
    en2idx, idx2en = ____________________________
    enc_voc = len(de2idx)
    dec_voc = len(en2idx)

    #TODO：初始化Transformer翻译模型
    model = _____________________________________
    print("AttModel PASS!")

    source_test = args.dataset_path + hp.source_test
    target_test = args.dataset_path + hp.target_test
    #TODO:构建测试数据集对象
    test_dataset = _____________________________________
    #TODO: 使用PyTorch的 DataLoader对测试集进行批量加载
    test_loader = _________________________(
        test_dataset,
        batch_size=_______________,
        shuffle=False,
        num_workers=______________,
        pin_memory=False)

    if args.device == "MLU":
        #model.to(ct.mlu_device())
        model.mlu()
    elif args.device == "GPU":
        model.cuda()
    #TODO: 从指定路径加载预训练模型参数
    state = ______________(______________, map_location='cpu')
    #TODO: 将加载的模型参数赋值到当前模型中，以完成模型权重的恢复
    ________________________________________
    if args.device == "MLU"  and args.cnmix:
        model, _ = cnmix.initialize(model, None, opt_level = args.opt_level)
        if isinstance(state, dict) and 'cnmix' in state:
            cnmix.load_state_dict(state['cnmix'])

    print('Model Loaded.')
    #TODO: 设置模型为评估模式
    ________________________________________

    #TODO: 以UTF-8编码、追加模式打开指定日志文件 args.log_path，用于记录模型评估的输出结果
    with _______________(args.log_path, 'a', 'utf-8') as fout:
        list_of_refs, hypotheses = [], []
        t1 = time.time()
        #TODO：遍历测试集，每次获取一个批次的输入数据、原始句子和目标句子
        for i, (_____________, _____________, _____________) in enumerate(test_loader):
            if (i == args.iterations):
                break
            # Autoregressive inference
            if args.device == "GPU":
                x_ = x.long().cuda()
                preds_t = torch.LongTensor(np.zeros((x.size()[0], hp.maxlen), np.int32)).cuda()
                preds = Variable(preds_t).cuda()
            elif args.device == "MLU":
                x_ = x.long().to('mlu')
                preds_t = torch.LongTensor(np.zeros((x.size()[0], hp.maxlen), np.int32)).to('mlu')
                preds = Variable(preds_t.to('mlu'))
            else:
                x_ = x.long()
                preds_t = torch.LongTensor(np.zeros((x.size()[0], hp.maxlen), np.int32))
                preds = Variable(preds_t)

            for j in range(hp.maxlen):
                _, _preds, _ = model(x_, preds)
                preds_t[:, j] = _preds.data[:, j]
                preds = Variable(preds_t.long())
            preds = preds.data.cpu().numpy()

            # Write to file
            for source, target, pred in zip(sources, targets, preds):  # sentence-wise
                got = " ".join(idx2en[idx] for idx in pred).split("</S>")[0].strip()
                fout.write("- source: " + source + "\n")
                fout.write("- expected: " + target + "\n")
                fout.write("- got: " + got + "\n\n")
                fout.flush()

                # bleu score
                ref = target.split()
                hypothesis = got.split()
                if len(ref) > 3 and len(hypothesis) > 3:
                    list_of_refs.append([ref])
                    hypotheses.append(hypothesis)
        #TODO：计算整个推理过程所消耗的总时间
        temp_time = ________________________
        print("time:",temp_time)
        #TODO：计算每秒处理的样本数（吞吐率）
        print("qps:",________________________)
        #TODO：计算模型翻译结果与参考答案之间的BLEU评分，用于评价翻译质量
        score = _________________(list_of_refs, hypotheses)
        fout.write("Bleu Score = " + str(100 * score))
        print("Bleu Score = {}".format(100 * score))
    if os.getenv('AVG_LOG'):
        with open(os.getenv('AVG_LOG'), 'a') as train_avg:
            train_avg.write('Bleu Score:{}\n'.format(100 * score))
    print("Eval PASS!")

if __name__ == '__main__':
    #TODO: 创建命令行参数解析器
    parser = ___________________________(description="Transformer evaluation.")
    parser.add_argument('--device', default='MLU', type=str, help='set the type of hardware used for evaluation.')
    parser.add_argument('--seed', default=0, type=int, help='random seed')
    parser.add_argument('--pretrained', default='model_epoch_20.pth', type=str, help='training ckps path')
    parser.add_argument('--batch-size', default=32, type=int, help='evaluation batch size.')
    parser.add_argument('--workers', default=4, type=int, help='number of workers.')
    parser.add_argument('--log-path', default='output.txt', type=str, help='evaluation file path.')
    parser.add_argument('--dataset-path', default='corpora/', type=str, help='The path of imagenet dataset.')
    parser.add_argument('--iterations', default=-1, type=int, help="Number of training iterations.")
    parser.add_argument('--bitwidth', default=8, type=int, help="Set the initial quantization width of network training.")
    parser.add_argument('--cnmix', action='store_true', default=False, help='use cnmix for mixed precision training')
    parser.add_argument('--opt_level', type=str, default="O0", help='choose level of mixing precision')
    #TODO:解析命令行输入的参数
    args = ___________________________

    if args.device == "MLU":
        import torch_mlu

    #TODO: 调用eval函数开始模型评估流程
    _________________________________
    if args.device == "MLU":
        print("Transformer MLU PASS!")
    else:
        print("Transformer CPU PASS!")



